{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# Speech Pronunciation Correction System Roadmap\n",
        "\n",
        "This notebook outlines a step-by-step roadmap for building a system that corrects pronunciations. The key steps in the process are:\n",
        "\n",
        "1. **Stream speech to text in phrases**\n",
        "2. **Send text to LLM to fix phrases**\n",
        "3. **Transform both texts in G2P responses**\n",
        "4. **Compare if the G2P responses are correct**\n",
        "5. **If incorrect, use TTS to help fix the pronunciation**\n",
        "\n",
        "Below you will find the detailed plan for each step along with references for further exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step1",
      "metadata": {},
      "source": [
        "## Step 1: Stream Speech to Text in Phrases\n",
        "\n",
        "**Objective:**\n",
        "- Capture live audio and segment it into meaningful phrases using a Speech-to-Text system.\n",
        "\n",
        "**Actions:**\n",
        "- Use real-time audio processing libraries (e.g., `pyaudio` or `sounddevice`).\n",
        "- Integrate Voice Activity Detection (VAD) to mark the boundaries of phrases.\n",
        "- Stream and transcribe each phrase individually."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step2",
      "metadata": {},
      "source": [
        "## Step 2: Send Text to LLM to Fix Phrases\n",
        "\n",
        "**Objective:**\n",
        "- Process the transcribed phrases with a Large Language Model (LLM) to refine and correct any errors.\n",
        "\n",
        "**Actions:**\n",
        "- Send each transcribed phrase to an LLM via an API or integrated model.\n",
        "- Craft prompts that specifically target pronunciation or phrasing issues.\n",
        "- Receive and store the corrected version of the text."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step3",
      "metadata": {},
      "source": [
        "## Step 3: Transform Both Texts into G2P Responses\n",
        "\n",
        "**Objective:**\n",
        "- Convert both the original and corrected texts into phonetic representations using a G2P (Grapheme-to-Phoneme) model.\n",
        "\n",
        "**Actions:**\n",
        "- Utilize a G2P tool (e.g., NVIDIA NeMo Toolkit G2P or the CiscoDevNet g2p_seq2seq_pytorch example) to transform text into phoneme sequences.\n",
        "- Obtain phonetic transcriptions for both the original and the LLM-corrected texts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step4",
      "metadata": {},
      "source": [
        "## Step 4: Compare G2P Responses\n",
        "\n",
        "**Objective:**\n",
        "- Compare the phonetic representations to determine if the correction has addressed the pronunciation issues.\n",
        "\n",
        "**Actions:**\n",
        "- Implement an algorithm to compare the two phoneme sequences (e.g., using edit distance or a similarity metric).\n",
        "- Identify discrepancies that indicate pronunciation errors have not been fully corrected."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step5",
      "metadata": {},
      "source": [
        "## Step 5: Use TTS to Help Fix the Pronunciation\n",
        "\n",
        "**Objective:**\n",
        "- Provide auditory feedback if the phonetic comparison reveals remaining issues.\n",
        "\n",
        "**Actions:**\n",
        "- Use a Text-to-Speech (TTS) engine (e.g., NVIDIA NeMo TTS or another high-quality TTS service) to generate speech from the corrected text.\n",
        "- Play the synthesized audio to the user so they can hear the corrected pronunciation.\n",
        "- Optionally, prompt the user to repeat the phrase and re-run the pipeline for further refinement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "references",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "- **Fixing Pronunciation in LLMs:**\n",
        "  - [ArXiv: Fixing Pronunciation in LLMs](https://arxiv.org/html/2404.02456v1)\n",
        "\n",
        "- **G2P Models:**\n",
        "  - [NVIDIA NeMo Toolkit G2P Documentation](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/tts/g2p.html)\n",
        "  - [CiscoDevNet g2p_seq2seq_pytorch Example](https://github.com/CiscoDevNet/g2p_seq2seq_pytorch)\n",
        "\n",
        "- **Speech-to-Text:**\n",
        "  - [OpenAI Whisper GitHub Repository](https://github.com/openai/whisper)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
